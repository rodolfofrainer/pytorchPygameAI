{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PyTorch Fundamentals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0.1+cpu\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "print(torch.__version__)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction to tensors\n",
    "\n",
    "### Creating Tensors\n",
    "\n",
    "PyTorch tensors are created using 'torch.tensor()' - https://pytorch.org/docs/stable/tensors.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(7)"
      ]
     },
     "execution_count": 358,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# scalar\n",
    "\n",
    "scalar = torch.tensor(7)\n",
    "scalar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 359,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scalar.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 360,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scalar.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "metadata": {},
   "outputs": [],
   "source": [
    "vector = torch.tensor([7,7])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 362,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2])"
      ]
     },
     "execution_count": 363,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 7,  8],\n",
       "        [ 9, 10]])"
      ]
     },
     "execution_count": 364,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# MATRIX\n",
    "\n",
    "MATRIX = torch.tensor([[7,8],[9,10]])\n",
    "\n",
    "MATRIX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 365,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MATRIX.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 9, 10])"
      ]
     },
     "execution_count": 366,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MATRIX[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(10)"
      ]
     },
     "execution_count": 367,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MATRIX[1][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 2])"
      ]
     },
     "execution_count": 368,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MATRIX.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[1, 2, 3],\n",
       "         [3, 6, 9],\n",
       "         [2, 4, 5]]])"
      ]
     },
     "execution_count": 369,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#TENSOR\n",
    "TENSOR = torch.tensor([[[1,2,3],[3,6,9],[2,4,5]]])\n",
    "TENSOR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 370,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TENSOR.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 371,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 3, 3])"
      ]
     },
     "execution_count": 371,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TENSOR.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Tensors\n",
    "\n",
    "Why random tensors?\n",
    "\n",
    "- Random tensors are important because the way many neural networks learn is that they start with tensors full of random numbers and the adjust those random numbers to better represent the data.\n",
    "\n",
    "`Start with random numbers -> look at data -> update numbers -> look at data -> rinse and repeat`\n",
    "\n",
    "https://pytorch.org/docs/stable/generated/torch.rand.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.2788, 0.2783, 0.7491, 0.4996],\n",
       "        [0.0701, 0.0079, 0.7044, 0.4881],\n",
       "        [0.3340, 0.0834, 0.6407, 0.0129]])"
      ]
     },
     "execution_count": 372,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a random tensor of shape (3,4)\n",
    "random_tensor = torch.rand(3,4)\n",
    "random_tensor\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 373,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([224, 224, 3]), 3)"
      ]
     },
     "execution_count": 373,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a random tensor with a similar shape to an image tensor\n",
    "\n",
    "random_image_tensor = torch.rand(size=(224,224,3)) # height, width, color channels (R,G,B)\n",
    "random_image_tensor.shape, random_image_tensor.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 374,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.9640, 0.5425, 0.7065, 0.6843, 0.9876],\n",
       "         [0.2103, 0.2987, 0.9127, 0.0529, 0.3302],\n",
       "         [0.0523, 0.6660, 0.2832, 0.5414, 0.0689],\n",
       "         [0.1231, 0.1471, 0.1401, 0.9072, 0.2996]],\n",
       "\n",
       "        [[0.4234, 0.8226, 0.5291, 0.5485, 0.4914],\n",
       "         [0.7085, 0.2813, 0.3230, 0.9131, 0.9609],\n",
       "         [0.5172, 0.2630, 0.3483, 0.0787, 0.7436],\n",
       "         [0.6764, 0.9439, 0.2124, 0.8137, 0.4640]],\n",
       "\n",
       "        [[0.1565, 0.3551, 0.0358, 0.0790, 0.7396],\n",
       "         [0.2175, 0.8547, 0.4632, 0.5786, 0.0152],\n",
       "         [0.6014, 0.6725, 0.1222, 0.0724, 0.7641],\n",
       "         [0.2613, 0.6326, 0.5678, 0.6439, 0.4200]]])"
      ]
     },
     "execution_count": 374,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_random_tensor = torch.rand(3,4,5)\n",
    "my_random_tensor"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Zeros and ones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 375,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 375,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a tensor of all zeros\n",
    "zeros = torch.zeros(3,4)\n",
    "zeros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1.]])"
      ]
     },
     "execution_count": 376,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ones = torch.ones(3,4)\n",
    "ones\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 377,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.float32"
      ]
     },
     "execution_count": 377,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ones.dtype"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a range of tensors and tensors-like\n",
    "\n",
    "https://pytorch.org/docs/stable/generated/torch.arange.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 378,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10])"
      ]
     },
     "execution_count": 378,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#use torch.arange()\n",
    "one_to_ten = torch.arange(start = 1,end = 11, step = 1)\n",
    "one_to_ten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 379,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#creating tensors like\n",
    "\n",
    "ten_zeroes = torch.zeros_like(one_to_ten)\n",
    "ten_zeroes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[3.4515e-02, 8.6159e-01, 1.4724e-01, 9.1493e-01, 1.0043e-01, 9.0258e-01,\n",
       "         6.6272e-01, 5.1734e-01, 9.1981e-01, 7.8100e-02, 6.2644e-01],\n",
       "        [7.7796e-01, 7.9613e-01, 2.9823e-01, 6.8968e-01, 7.7254e-02, 9.5762e-01,\n",
       "         6.0181e-01, 3.7575e-04, 1.5251e-01, 9.7523e-01, 6.8073e-01],\n",
       "        [3.0240e-01, 1.1861e-01, 7.5229e-01, 5.9753e-01, 7.9769e-04, 3.2792e-01,\n",
       "         6.8272e-01, 8.7556e-01, 1.0103e-01, 7.4429e-01, 5.4129e-01],\n",
       "        [6.5025e-01, 2.0358e-01, 4.8914e-02, 2.4520e-01, 1.9229e-02, 8.5250e-01,\n",
       "         5.2824e-01, 6.9748e-01, 8.6407e-01, 5.3870e-01, 4.7365e-01],\n",
       "        [5.0696e-02, 5.3286e-01, 1.6962e-01, 8.7104e-01, 7.5622e-01, 7.3014e-01,\n",
       "         4.5876e-01, 3.7396e-01, 9.9274e-01, 2.5451e-01, 1.9624e-01],\n",
       "        [4.9837e-01, 7.6884e-01, 1.7999e-01, 7.7862e-01, 2.8856e-01, 8.0137e-01,\n",
       "         9.9239e-01, 8.4373e-01, 4.5091e-01, 3.2073e-01, 3.7192e-01],\n",
       "        [8.4039e-01, 6.1300e-02, 3.6882e-02, 9.1912e-01, 6.9462e-01, 7.2098e-01,\n",
       "         8.0542e-01, 5.3947e-01, 3.5248e-01, 3.1762e-02, 3.8659e-01]])"
      ]
     },
     "execution_count": 380,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seven_by_eleven = torch.rand(7,11)\n",
    "seven_by_eleven"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 381,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 381,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seven_zeroes = torch.zeros_like(seven_by_eleven)\n",
    "seven_zeroes"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tensor datatypes\n",
    "\n",
    "**Note:** Tensor datatypes is one of the 3 big error one runs into with PyTorch & deep learning:\n",
    "1. Tensors not right datatype\n",
    "2. tensors not right shape\n",
    "3. tensors not on the right device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 382,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([3., 6., 9.])"
      ]
     },
     "execution_count": 382,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Float 32 tensor\n",
    "\n",
    "float_32_tensor = torch.tensor(\n",
    "    [3.0,6.0,9.0],\n",
    "    dtype=None, # what data type is the tensor\n",
    "    device=None, # where to store the tensor (CPU or GPU)\n",
    "    requires_grad=False # whether to keep track of the gradients for this tensors operations\n",
    "    )\n",
    "float_32_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 383,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.float32"
      ]
     },
     "execution_count": 383,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "float_32_tensor.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 384,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([3., 6., 9.], dtype=torch.float16)"
      ]
     },
     "execution_count": 384,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "float_16_tensor = float_32_tensor.type(torch.float16)\n",
    "float_16_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 385,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.float32"
      ]
     },
     "execution_count": 385,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "multiplication_float = float_16_tensor*float_32_tensor\n",
    "multiplication_float.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 386,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 27., 216., 729.], dtype=torch.float64)"
      ]
     },
     "execution_count": 386,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "float_64_tensor = float_32_tensor.type(torch.float64)\n",
    "multiplication_float = float_64_tensor*float_16_tensor*float_32_tensor\n",
    "\n",
    "multiplication_float"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting information from tensors\n",
    "1. Tensors not right datatype - To get datatype from tensor can user 'tensor.dtype'\n",
    "2. tensors not right shape - to get shape can use 'tensor.shape'\n",
    "3. tensors not on the right device - to get device can use 'tensor.device'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 387,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.8298, 0.2158, 0.1865, 0.1935],\n",
       "        [0.0216, 0.8054, 0.0544, 0.6569],\n",
       "        [0.8023, 0.7710, 0.4169, 0.3997]])"
      ]
     },
     "execution_count": 387,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a tensor\n",
    "\n",
    "some_tensor = torch.rand(3,4)\n",
    "some_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 388,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensions Of Tensor: 2\n",
      "Shape Of Tensor: Torch.Size([3, 4])\n",
      "Type Of Tensor: Torch.Float32\n",
      "Device Of Tensor: Cpu\n"
     ]
    }
   ],
   "source": [
    "# find detail about tensor\n",
    "\n",
    "print(f'dimensions of tensor: {some_tensor.ndim}'.title())\n",
    "print(f'shape of tensor: {some_tensor.shape}'.title())\n",
    "print(f'type of tensor: {some_tensor.dtype}'.title())\n",
    "print(f'device of tensor: {some_tensor.device}'.title())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 389,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 389,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#cuda not available\n",
    "\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Manipulating tensors (tensor operations)\n",
    "\n",
    "#### Tensor operations include:\n",
    "- Addition\n",
    "- Substraction\n",
    "- Multiplication(element-wise)\n",
    "- Division\n",
    "- Matrix Multiplication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 390,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([11, 12, 13])"
      ]
     },
     "execution_count": 390,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a tensor\n",
    "tensor = torch.tensor([1,2,3])\n",
    "\n",
    "#Add 10 to each element\n",
    "tensor += 10\n",
    "tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 391,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([110, 120, 130])"
      ]
     },
     "execution_count": 391,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Multiply each element by 10\n",
    "tensor *= 10\n",
    "tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 392,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-9, -8, -7])"
      ]
     },
     "execution_count": 392,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# subtract 10 from each element\n",
    "tensor = torch.tensor([1,2,3])\n",
    "tensor -= 10\n",
    "tensor"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Matrix Multiplication\n",
    "\n",
    "Two main ways of performing multiplication in neural networks and deep learning:\n",
    "\n",
    "1. element-wise multiplication\n",
    "2. matrix multiplication (dot product)\n",
    "\n",
    "There are two main rules that performin matrix multiplication needs to satisfy:\n",
    "1. the **inner dimmentions** must match:\n",
    "    - `torch.matmul((3,2), (3,2))` this won't work\n",
    "    - `torch.matmul((3,2), (2,3))` this will work\n",
    "    - `torch.matmul((2,3), (3,2))` this will work\n",
    "2. the resultin matrix has the result of the **outer dimensions**:\n",
    "   - `(2,3) @ (3,2)` -> `(2,2)`\n",
    "\n",
    "    *@ means multiplication*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 393,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1, 2, 3]) * tensor([1, 2, 3]) = tensor([1, 4, 9])\n"
     ]
    }
   ],
   "source": [
    "# Element wise multiplication\n",
    "tensor = torch.tensor([1,2,3])\n",
    "print(tensor, '*', tensor, '=', tensor*tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 394,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(14)"
      ]
     },
     "execution_count": 394,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Matrix multiplication\n",
    "torch.matmul(tensor, tensor)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One of the most common errors in deep learning i shape errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 395,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shapes for matrix multiplications\n",
    "\n",
    "tensor_A = torch.tensor([\n",
    "    [1,2],\n",
    "    [3,4],\n",
    "    [5,6]\n",
    "    ])\n",
    "tensor_B = torch.tensor([\n",
    "    [7,8],\n",
    "    [9,10],\n",
    "    [11,12]\n",
    "    ])\n",
    "\n",
    "# RuntimeError: mat1 and mat2 shapes cannot be multiplied (3x2 and 3x2)\n",
    "# torch.mm(tensor_A, tensor_B)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### To fix this error we have to ***tranpose*** the tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 396,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 23,  29,  35],\n",
       "        [ 53,  67,  81],\n",
       "        [ 83, 105, 127]])"
      ]
     },
     "execution_count": 396,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.mm(tensor_A, tensor_B.T)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
